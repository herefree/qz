#### 大数据面试

https://github.com/Dr11ft/BigDataGuide

HDFS架构

NameNode：一个，单点问题 ==>HA

​                         metadata:谁创建的 权限 文件对应的block信息

DataNode：多个 存数据 和NN之间有心跳

SecondaryNameNode

Block：File存入HDFS，是按照block进行划分  128M

hdfs写流程：

1）client端发送写文件请求，namenode检查文件是否存在，如果已存在，直接返回错误信息，否则，发送给client一些可用datanode节点

2）client将文件分块，并行存储到不同节点上datanode上，发送完成后，client同时发送信息给namenode和datanode

3）namenode收到的client信息后，发送确信信息给datanode

4）datanode同时收到namenode和datanode的确认信息后，提交写操作。

hdfs读流程：

1）client端发送读文件请求给namenode，如果文件不存在，返回错误信息，否则，将该文件对应的block及其所在datanode位置发送给client

2） client收到文件位置信息后，与不同datanode建立socket连接并行获取数据。

HDFS HA架构：



yarn架构HA：



**小文件是什么？**

小文件是指文件size小于HDFS上block大小的文件。这样的文件会给Hadoop的扩展性和性能带来严重问题。首先，在HDFS中，任何block，文件或者目录在内存中均以对象的形式存储，每个对象约占150byte，如果有1000 0000个小文件，每个文件占用一个block，则namenode大约需要2G空间。如果存储1亿个文件，则namenode需要20G空间（见参考资料[1][4][5]）。这样namenode内存容量严重制约了集群的扩展。

 其次，访问大量小文件速度远远小于访问几个大文件。

1.磁盘IO 2.map数量多（资源有限）3.task启动销毁的开销

**HDFS为什么会有小文件？**

1.数据源小文件 搬到hdfs

2.mapreduce 或spark作业时，reduce 决定输出文件数目 编程没有做很好的设置

**如何解决小文件问题？**

**行式存储列式存储**

